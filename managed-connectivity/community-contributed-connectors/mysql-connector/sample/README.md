# Sample Metadata Import File
This directory contains:
 * A sample metadata file generated by the connector: [mysql-sample-output-classicmodels.jsonl](mysql-sample-output-classicmodels.jsonl)
 * A request to use with the Metadata Import REST API: [metadata_import_request.json](metadata_import_request.json)

### Import metadata into universal catalog

* In [mysql-sample-output-classicmodels.jsonl](mysql-sample-output-classicmodels.jsonl): 
    1. Search and replace all instances of "gcp-project-id" with your project ID
    2. [OPTIONAL] Search and replace all instances of "us-central1" with your region or with "global" 
    3. Upload the file to a Google Cloud Storage bucket

* In [metadata_import_request.json](metadata_import_request.json):
    1. Replace the value in source_storage_uri with the path to your Cloud Storage bucket from above (Note: without the file and ending with /)
    2. Replace "gcp-project-id" with your project ID
    3. Go to the Dataplex UI. Ensure the Entry Group, Entry Types and Aspect Types seen in metadata_import_request.json exist in your project
        
        Note: projects/dataplex-types/locations/global/aspectTypes/schema is a built-in Aspect Type and does not need to be created.

Run import via the REST Metadata Import API, replacing gcp-project-id below for your project, and us-central1 with another location if appropriate:

```bash
curl -X POST -H "Authorization: Bearer $(gcloud auth print-access-token)" \
-H "Content-Type: application/json; charset=utf-8" \
-d @metadata_import_request.json \
"https://dataplex.googleapis.com/v1/projects/the-project-id/locations/us-central1/metadataJobs?metadataJobId=a001"
```

For more details about the Metadata Import process see [the documentation](https://cloud.google.com/dataplex/docs/import-metadata#import-metadata)